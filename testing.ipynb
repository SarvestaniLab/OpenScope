{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following instructions here: https://alleninstitute.github.io/openscope_databook/basics/download_nwb.html\n",
    "#run using openscope environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from databook_utils.dandi_utils import dandi_stream_open\n",
    "except:\n",
    "    !git clone https://github.com/AllenInstitute/openscope_databook.git\n",
    "    %cd openscope_databook\n",
    "    %pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "\n",
    "from dandi import dandiapi\n",
    "from pynwb import NWBHDF5IO\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "from nwbwidgets.view import default_neurodata_vis_spec\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pynwb\n",
    "from nwbwidgets import nwb2widget\n",
    "\n",
    "\n",
    "from typing import Union, Iterator, Callable, Tuple, Dict\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to download files with a progress bar\n",
    "\n",
    "MAX_CHUNK_SIZE = int(os.environ.get(\"DANDI_MAX_CHUNK_SIZE\", 1024 * 1024 * 8))  \n",
    "\n",
    "def get_download_file_iter_with_steps(\n",
    "    file, chunk_size: int = MAX_CHUNK_SIZE\n",
    ") -> Tuple[Callable[[int], Iterator[bytes]], Dict[str, int]]:\n",
    "\n",
    "    url = file.base_download_url\n",
    "    steps_dict = {\"total_steps\": None}\n",
    "    result = file.client.session.get(url, stream=True)\n",
    "\n",
    "    total_size = int(result.headers.get('content-length', 0))\n",
    "    steps_dict[\"total_steps\"] = total_size // chunk_size\n",
    "    print(f\"Downloading {total_size} bytes in {steps_dict['total_steps']} steps\")\n",
    "\n",
    "    def downloader(start_at: int = 0) -> Iterator[bytes]:\n",
    "        headers = None\n",
    "        if start_at > 0:\n",
    "            headers = {\"Range\": f\"bytes={start_at}-\"}\n",
    "        result = file.client.session.get(url, stream=True, headers=headers)\n",
    "        result.raise_for_status()\n",
    "        for chunk in result.iter_content(chunk_size=chunk_size):\n",
    "            if chunk:  \n",
    "                yield chunk\n",
    "\n",
    "    return downloader, steps_dict\n",
    "\n",
    "def download_with_progressbar(\n",
    "    file, filepath: Union[str, Path], chunk_size: int = MAX_CHUNK_SIZE\n",
    ") -> None:\n",
    "    downloader, steps_dict = get_download_file_iter_with_steps(file)\n",
    "    with open(filepath, \"wb\") as fp:\n",
    "        for chunk in tqdm(downloader(0), total=steps_dict[\"total_steps\"], unit=\"chunk\", unit_scale=True, unit_divisor=1024):\n",
    "            fp.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Average Receptive Field Across Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "load_dotenv(dotenv_path=\"config.env\")\n",
    "\n",
    "download_loc = os.getenv(\"SAMPLE_DATA_DIR\")\n",
    "print(download_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got dandiset DANDI:000021/draft\n",
      "None/sub-699733573_ses-715093703.nwb\n",
      "Downloading 2856232912 bytes in 340 steps\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'None/sub-699733573_ses-715093703.nwb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m file \u001b[38;5;241m=\u001b[39m my_dandiset\u001b[38;5;241m.\u001b[39mget_asset_by_path(dandi_filepath)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# this may take awhile, especially if the file to download is large\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mdownload_with_progressbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m, in \u001b[0;36mdownload_with_progressbar\u001b[0;34m(file, filepath, chunk_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload_with_progressbar\u001b[39m(\n\u001b[1;32m     30\u001b[0m     file, filepath: Union[\u001b[38;5;28mstr\u001b[39m, Path], chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m MAX_CHUNK_SIZE\n\u001b[1;32m     31\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     downloader, steps_dict \u001b[38;5;241m=\u001b[39m get_download_file_iter_with_steps(file)\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m tqdm(downloader(\u001b[38;5;241m0\u001b[39m), total\u001b[38;5;241m=\u001b[39msteps_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m], unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m):\n\u001b[1;32m     35\u001b[0m             fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/openscope/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'None/sub-699733573_ses-715093703.nwb'"
     ]
    }
   ],
   "source": [
    "dandiset_id = \"000021\"\n",
    "dandi_filepath = \"sub-699733573/sub-699733573_ses-715093703.nwb\"\n",
    "\n",
    "dandi_api_key = None\n",
    "authenticate = False\n",
    "\n",
    "\n",
    "if authenticate:\n",
    "    client = dandiapi.DandiAPIClient(token=dandi_api_key)\n",
    "else:\n",
    "    client = dandiapi.DandiAPIClient()\n",
    "my_dandiset = client.get_dandiset(dandiset_id,\"draft\")\n",
    "\n",
    "print(f\"Got dandiset {my_dandiset}\")\n",
    "\n",
    "filename = dandi_filepath.split(\"/\")[-1]\n",
    "filepath = f\"{download_loc}\\{filename}\" if os.name == 'nt' else f\"{download_loc}/{filename}\"\n",
    "print(filepath)\n",
    "\n",
    "file = my_dandiset.get_asset_by_path(dandi_filepath)\n",
    "# this may take awhile, especially if the file to download is large\n",
    "download_with_progressbar(file, filepath)\n",
    "\n",
    "print(f\"Downloaded file to {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and Display the NWB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ROOT_DIR \u001b[38;5;241m=\u001b[39m download_loc\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Look for the first NWB file under the dandiset folder\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m candidates \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mROOT_DIR\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.nwb\u001b[39m\u001b[38;5;124m\"\u001b[39m), recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo .nwb file found under \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m ROOT_DIR)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/openscope/lib/python3.10/pathlib.py:960\u001b[0m, in \u001b[0;36mPath.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    963\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/openscope/lib/python3.10/pathlib.py:594\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 594\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/openscope/lib/python3.10/pathlib.py:578\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    576\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[1;32m    581\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "# open the downloaded NWB file\n",
    "ROOT_DIR = download_loc\n",
    "\n",
    "# Look for the first NWB file under the dandiset folder\n",
    "candidates = glob.glob(str(Path(ROOT_DIR) / \"**\" / \"*.nwb\"), recursive=True)\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(\"No .nwb file found under \" + ROOT_DIR)\n",
    "nwb_path = candidates[0]\n",
    "print(\"Opening:\", nwb_path)\n",
    "io = NWBHDF5IO(nwb_path, \"r\", load_namespaces=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwb = io.read()\n",
    "print(nwb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_stim_table = nwb.intervals[\"gabors_presentations\"].to_dataframe()\n",
    "rf_stim_table[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening another nwb file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nwb_path = r\"C:\\Users\\MaryBeth\\projects\\SarvestaniLab\\OpenScopeMouseV1\\001568\\sub-810531\\sub-810531_ses-ecephys-810531-2025-09-17-15-14-30_ecephys.nwb\"\n",
    "\n",
    "# io = NWBHDF5IO(nwb_path, \"r\", load_namespaces=True)\n",
    "# nwb = io.read()\n",
    "\n",
    "# print(nwb)\n",
    "            \n",
    "# units = nwb.units\n",
    "# units.colnames\n",
    "# nwb.intervals.keys()\n",
    "# channel_probes = {nwb.electrodes[\"id\"][i]: nwb.electrodes[\"group_name\"][i] for i in range(len(nwb.electrodes))}\n",
    "\n",
    "# # function retrieves peak channel ID from \"units\" dataset, looks up corresponding group name, returns probe associated with peak channel\n",
    "# def get_unit_probe(unit_idx):\n",
    "#     return str(units['device_name'][unit_idx])\n",
    "\n",
    "# print(set(channel_probes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve probe names\n",
    "channel_probes = {nwb.electrodes[\"id\"][i]: nwb.electrodes[\"group_name\"][i] for i in range(len(nwb.electrodes))}\n",
    "\n",
    "# function retrieves peak channel ID from \"units\" dataset, looks up corresponding group name, returns probe associated with peak channel\n",
    "def get_unit_probe(unit_idx):\n",
    "    peak_channel_id = units[\"peak_channel_id\"][unit_idx]\n",
    "    return channel_probes[peak_channel_id]\n",
    "\n",
    "print(set(channel_probes.values()))\n",
    "## Get units from selected probe & their receptive fields\n",
    "### helper functions made from electrodes table to get brain location of unit or probe name of unit\n",
    "\n",
    "# map channel ids to brain location and probe group name\n",
    "# creates a dictionary that iterates over indices of the dataset, assigns \"id\" as the key, and makes the location the value\n",
    "channel_locations = {nwb.electrodes[\"id\"][i]: nwb.electrodes[\"location\"][i] for i in range(len(nwb.electrodes))}\n",
    "# creates similar dictionary as previous line, but with the group name/probe name as the value\n",
    "channel_probes = {nwb.electrodes[\"id\"][i]: nwb.electrodes[\"group_name\"][i] for i in range(len(nwb.electrodes))}\n",
    "\n",
    "# function retrieves peak channel ID for given unit index from \"units\" dataset and looks up corresponding probe from dictionary\n",
    "def get_unit_location(unit_idx):\n",
    "    peak_channel_id = units[\"peak_channel_id\"][unit_idx]\n",
    "    return channel_locations[peak_channel_id]\n",
    "\n",
    "# function retrieves peak channel ID from \"units\" dataset, looks up corresponding group name, returns probe associated with peak channel\n",
    "def get_unit_probe(unit_idx):\n",
    "    peak_channel_id = units[\"peak_channel_id\"][unit_idx]\n",
    "    return channel_probes[peak_channel_id]\n",
    "\n",
    "print(set(channel_locations.values()))\n",
    "print(set(channel_probes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'units' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m units[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnr\u001b[39m\u001b[38;5;124m\"\u001b[39m][unit_idx] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m      6\u001b[0m             get_unit_probe(unit_idx) \u001b[38;5;241m==\u001b[39m probe\n\u001b[1;32m      8\u001b[0m selected_unit_idxs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m unit_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43munits\u001b[49m)):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m select_condition(unit_idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobeB\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     11\u001b[0m         selected_unit_idxs\u001b[38;5;241m.\u001b[39mappend(unit_idx)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'units' is not defined"
     ]
    }
   ],
   "source": [
    "def select_condition(unit_idx, probe, all_units=False):\n",
    "    # the values below are recommended thresholds for these quality metrics\n",
    "    if all_units:\n",
    "        return True\n",
    "    return units[\"snr\"][unit_idx] > 1 and \\\n",
    "            get_unit_probe(unit_idx) == probe\n",
    "\n",
    "selected_unit_idxs = []\n",
    "for unit_idx in range(len(units)):\n",
    "    if select_condition(unit_idx, \"probeB\"):\n",
    "        selected_unit_idxs.append(unit_idx)\n",
    "        \n",
    "if len(selected_unit_idxs) == 0:\n",
    "    raise IndexError(\"There are no units for this selection\")\n",
    "\n",
    "print(len(selected_unit_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_stim_table.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_stim_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### get x and y coordinates of gabors displayed to build receptive field\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m xs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mrf_stim_table\u001b[49m\u001b[38;5;241m.\u001b[39mx_position)))\n\u001b[1;32m      4\u001b[0m ys \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(rf_stim_table\u001b[38;5;241m.\u001b[39my_position)))\n\u001b[1;32m      5\u001b[0m field_units \u001b[38;5;241m=\u001b[39m rf_stim_table\u001b[38;5;241m.\u001b[39munits[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_stim_table' is not defined"
     ]
    }
   ],
   "source": [
    "### get x and y coordinates of gabors displayed to build receptive field\n",
    "\n",
    "xs = np.sort(list(set(rf_stim_table.x_position)))\n",
    "ys = np.sort(list(set(rf_stim_table.y_position)))\n",
    "field_units = rf_stim_table.units[0]\n",
    "print(xs)\n",
    "print(ys)\n",
    "print(field_units)\n",
    "\n",
    "\n",
    "### get receptive field of a unit using its spike times and the stim table\n",
    "\n",
    "def get_rf(spike_times):\n",
    "    # creates 2D array that stores response spike counts for each coordinate of the receptive field\n",
    "    unit_rf = np.zeros([ys.size, xs.size])\n",
    "    # for every x and y coordinate in the field\n",
    "    for xi, x in enumerate(xs):\n",
    "        for yi, y in enumerate(ys):\n",
    "            \n",
    "            # for this coordinate of the rf, count all the times that this neuron responds to a stimulus time with a spike\n",
    "            stim_times = rf_stim_table[(rf_stim_table.x_position == x) & (rf_stim_table.y_position == y)].start_time\n",
    "            response_spike_count = 0\n",
    "            for stim_time in stim_times:\n",
    "                # any spike within 0.2 seconds after stim time is considered a response\n",
    "                start_idx, end_idx = np.searchsorted(spike_times, [stim_time, stim_time+0.2])\n",
    "                response_spike_count += end_idx-start_idx\n",
    "\n",
    "            unit_rf[yi, xi] = response_spike_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute receptive fields for each unit in selected units\n",
    "\n",
    "unit_rfs = []\n",
    "for unit_idx in selected_unit_idxs:\n",
    "    unit_spike_times = units[\"spike_times\"][unit_idx]\n",
    "    unit_rfs.append(get_rf(unit_spike_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot in cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unit_rfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Random positions\u001b[39;00m\n\u001b[1;32m     11\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m n_rfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43munit_rfs\u001b[49m)\n\u001b[1;32m     13\u001b[0m x_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, n_rfs)\n\u001b[1;32m     14\u001b[0m y_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, n_rfs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unit_rfs' is not defined"
     ]
    }
   ],
   "source": [
    "### Plotly with COLOR\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Random positions\n",
    "np.random.seed(42)\n",
    "n_rfs = len(unit_rfs)\n",
    "x_positions = np.random.uniform(0, 10, n_rfs)\n",
    "y_positions = np.random.uniform(0, 10, n_rfs)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter points (clickable)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_positions,\n",
    "    y=y_positions,\n",
    "    mode='markers',\n",
    "    marker=dict(size=20, color='lightblue', line=dict(width=1, color='black')),\n",
    "    text=[f\"Unit {i}\" for i in range(n_rfs)],\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Add RF images as layout images with COLOR\n",
    "for i, (rf, x, y) in enumerate(zip(unit_rfs, x_positions, y_positions)):\n",
    "    # Normalize RF for display (0-1 range)\n",
    "    rf_norm = (rf - rf.min()) / (rf.max() - rf.min()) if rf.max() > rf.min() else rf\n",
    "    \n",
    "    # Apply colormap (RdBu_r) to get RGB image\n",
    "    cmap = cm.get_cmap('viridis')  # You can change this: 'viridis', 'plasma', 'hot', etc.\n",
    "    rf_colored = cmap(rf_norm)  # This returns RGBA\n",
    "    \n",
    "    # Convert to uint8 RGB (drop alpha channel)\n",
    "    rf_uint8 = (rf_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert to PIL Image\n",
    "    img = Image.fromarray(rf_uint8, mode='RGB')\n",
    "    \n",
    "    # Convert to base64 string\n",
    "    buffered = io.BytesIO()\n",
    "    img.save(buffered, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "    \n",
    "    fig.add_layout_image(\n",
    "        dict(\n",
    "            source=f\"data:image/png;base64,{img_str}\",\n",
    "            x=x - 0.3,\n",
    "            y=y + 0.3,\n",
    "            sizex=0.6,\n",
    "            sizey=0.6,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            opacity=1.0,\n",
    "            layer=\"above\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=900,\n",
    "    xaxis=dict(\n",
    "        range=[-0.5, 10.5],\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        showticklabels=False,  # <-- Hide x tick labels\n",
    "        visible=False           # <-- Hide x-axis entirely\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        range=[-0.5, 10.5],\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        showticklabels=False,  # <-- Hide y tick labels\n",
    "        visible=False           # <-- Hide y-axis entirely\n",
    "    ),\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the AVERAGE receptive field\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate average RF\n",
    "average_rf = np.mean(unit_rfs, axis=0)\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot average RF with colorbar\n",
    "im = ax.imshow(average_rf, origin=\"lower\", cmap='viridis')\n",
    "ax.set_xlabel(field_units)\n",
    "ax.set_ylabel(field_units)\n",
    "#ax.set_title(f'Average Receptive Field (n={len(unit_rfs)} units)', fontsize=14)\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xticks(range(len(xs)))\n",
    "ax.set_xticklabels(xs, rotation=90, fontsize=8)\n",
    "ax.set_yticks(range(len(ys)))\n",
    "ax.set_yticklabels(ys, fontsize=8)\n",
    "\n",
    "# Show every other tick label for clarity\n",
    "for i, l in enumerate(ax.xaxis.get_ticklabels()):\n",
    "    if i % 2 != 0:\n",
    "        l.set_visible(False)\n",
    "for i, l in enumerate(ax.yaxis.get_ticklabels()):\n",
    "    if i % 2 != 0:\n",
    "        l.set_visible(False)\n",
    "\n",
    "# # Add colorbar\n",
    "# cbar = plt.colorbar(im, ax=ax)\n",
    "# cbar.set_label('Average Response', rotation=270, labelpad=20)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Print statistics\n",
    "print(f\"Average RF shape: {average_rf.shape}\")\n",
    "print(f\"Average RF min: {average_rf.min():.4f}\")\n",
    "print(f\"Average RF max: {average_rf.max():.4f}\")\n",
    "print(f\"Average RF mean: {average_rf.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
